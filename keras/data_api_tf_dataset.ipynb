{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32fa81f9-4e32-48ee-a307-635e1071c704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jcolamendy/python/tutorials/ml-tutorials/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf34e01c-0898-492d-a7a6-7a4e85b94c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [1 2] <class 'tensorflow.python.framework.ops.EagerTensor'> Label: 0 <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Features: [3 4] <class 'tensorflow.python.framework.ops.EagerTensor'> Label: 1 <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Features: [5 6] <class 'tensorflow.python.framework.ops.EagerTensor'> Label: 0 <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 08:13:18.840059: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "features = np.array([[1, 2], [3, 4], [5, 6]])  # Example features\n",
    "labels = np.array([0, 1, 0])  # Corresponding labels\n",
    "\n",
    "# Create a Dataset of slices\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "for feature, label in dataset:\n",
    "    print('Features:', feature.numpy(), type(feature), 'Label:', label.numpy(), type(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33533489-2dd3-41b0-8344-7241df76d75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 0, <class 'tensorflow.python.framework.ops.EagerTensor'>, y: 0, <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "x: 1, <class 'tensorflow.python.framework.ops.EagerTensor'>, y: 1, <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "x: 2, <class 'tensorflow.python.framework.ops.EagerTensor'>, y: 4, <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "x: 3, <class 'tensorflow.python.framework.ops.EagerTensor'>, y: 9, <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "x: 4, <class 'tensorflow.python.framework.ops.EagerTensor'>, y: 16, <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "x: 5, <class 'tensorflow.python.framework.ops.EagerTensor'>, y: 25, <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "x: 6, <class 'tensorflow.python.framework.ops.EagerTensor'>, y: 36, <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "x: 7, <class 'tensorflow.python.framework.ops.EagerTensor'>, y: 49, <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "x: 8, <class 'tensorflow.python.framework.ops.EagerTensor'>, y: 64, <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "x: 9, <class 'tensorflow.python.framework.ops.EagerTensor'>, y: 81, <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 08:14:38.354816: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Define a Python generator function\n",
    "def data_generator():\n",
    "    for i in range(10):\n",
    "        yield (i, i**2)\n",
    "\n",
    "# Create a dataset using from_generator()\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    data_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Iterate over the dataset and print the elements\n",
    "for x, y in dataset:\n",
    "    print(f\"x: {x.numpy()}, {type(x)}, y: {y.numpy()}, {type(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71375b1e-711a-40cb-a11c-9354576be570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset'>\n",
      "preprocess Tensor(\"args_0:0\", shape=(), dtype=string) Tensor(\"args_1:0\", shape=(), dtype=int32)\n",
      "<class 'tensorflow.python.data.ops.map_op._MapDataset'>\n",
      "<class 'tensorflow.python.data.ops.cache_op.CacheDataset'>\n",
      "<class 'tensorflow.python.data.ops.shuffle_op._ShuffleDataset'>\n",
      "<class 'tensorflow.python.data.ops.batch_op._BatchDataset'>\n",
      "<class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n",
      "x: [[1 2]\n",
      " [3 4]\n",
      " [1 2]\n",
      " [3 4]], <class 'tensorflow.python.framework.ops.EagerTensor'>, y: [0 1 0 1], <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 08:36:46.968785: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "/Users/jcolamendy/python/tutorials/ml-tutorials/venv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-04-26 08:36:47.268105: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659ms/step - accuracy: 0.5000 - loss: 1.3823\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5000 - loss: 1.3804\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5000 - loss: 1.3786\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 1.3767\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 1.3748\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.5000 - loss: 1.3730\n",
      "Test Loss: 1.3730\n",
      "Test Accuracy: 0.5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Input: [[1 2]\n",
      " [3 4]\n",
      " [1 2]\n",
      " [3 4]], True Label: [0 1 0 1], Predicted Label: 0.9357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 08:36:47.994532: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Suppose we have lists of image file paths and corresponding labels\n",
    "file_paths = ['path/to/image1.jpg', 'path/to/image2.jpg', 'path/to/image1.jpg', 'path/to/image2.jpg']\n",
    "labels = [0, 1, 0, 1]  # Example binary labels for two classes\n",
    "\n",
    "# Step 1: Load the raw data\n",
    "dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "print(type(dataset))\n",
    "\n",
    "# Step 2: Apply preprocessing transformations\n",
    "def preprocess_data(file_path, label):\n",
    "    # img = tf.io.read_file(file_path)\n",
    "    # img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # img = tf.image.resize(img, [150, 150])  # Resize to 150x150 pixels\n",
    "    # img = img / 255.0  # Normalize pixel values\n",
    "    # return img, label\n",
    "    print('preprocess', file_path, label)\n",
    "    res = np.array([1, 2])\n",
    "    if label == 1:\n",
    "        res = np.array([3, 4])\n",
    "    return res, label\n",
    "\n",
    "dataset = dataset.map(preprocess_data)\n",
    "print(type(dataset))\n",
    "\n",
    "# Step 3: Cache the preprocessed data\n",
    "dataset = dataset.cache()\n",
    "print(type(dataset))\n",
    "\n",
    "# Step 4: Shuffle the data\n",
    "dataset = dataset.shuffle(buffer_size=1000)\n",
    "print(type(dataset))\n",
    "\n",
    "# Step 5: Batch the data\n",
    "batch_size = 32\n",
    "dataset = dataset.batch(batch_size)\n",
    "print(type(dataset))\n",
    "\n",
    "# Step 6: Prefetch the batches\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "print(type(dataset))\n",
    "\n",
    "# Iterate over the dataset and print the elements\n",
    "for x, y in dataset:\n",
    "    print(f\"x: {x.numpy()}, {type(x)}, y: {y.numpy()}, {type(y)}\")\n",
    "\n",
    "# process the dataset\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', input_shape=(2,))\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "epochs = 5\n",
    "model.fit(dataset, epochs=epochs)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(dataset)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(dataset)\n",
    "for pred, (x, y) in zip(predictions, dataset):\n",
    "    print(f\"Input: {x.numpy()}, True Label: {y.numpy()}, Predicted Label: {pred[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b10d00a9-b84f-4361-9b24-072ff47e0c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[-0.1470271   1.0276992 ]\n",
      " [ 0.23964654  0.47124095]\n",
      " [-0.28314591  0.26677781]\n",
      " [-0.32696773  0.76038779]], <class 'numpy.ndarray'>, y: [1 4 6 7], <class 'numpy.ndarray'>\n",
      "x: [[-0.54288201  1.21177727]\n",
      " [ 0.50617934 -0.94575796]\n",
      " [ 0.42918511 -1.17319623]\n",
      " [-0.33027218 -1.25989641]], <class 'numpy.ndarray'>, y: [8 2 8 3], <class 'numpy.ndarray'>\n",
      "Epoch 1/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 0.4356  \n",
      "Epoch 2/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1667 - loss: 0.0600 \n",
      "Epoch 3/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2500 - loss: 0.6232 \n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jcolamendy/python/tutorials/ml-tutorials/venv/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2500 - loss: 0.1719\n",
      "Epoch 5/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1667 - loss: 1.1418\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2500 - loss: 1.2647 \n",
      "Test Loss: 1.0381\n",
      "Test Accuracy: 0.2500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Input: [[ 0.58311801  0.18819553]\n",
      " [-0.54288201  1.21177727]\n",
      " [-0.19829194  0.4973531 ]\n",
      " [-0.28314591  0.26677781]], True Label: [0 8 0 6], Predicted Label: 0.4569\n",
      "Input: [[ 0.50617934 -0.94575796]\n",
      " [-0.32696773  0.76038779]\n",
      " [-0.1470271   1.0276992 ]\n",
      " [-0.33027218 -1.25989641]], True Label: [2 7 1 3], Predicted Label: 0.4037\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.utils import Sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Define a custom data generator for Keras\n",
    "class KerasDataGenerator(Sequence):\n",
    "    def __init__(self, data, targets, batch_size=32, shuffle=True, transform=None):\n",
    "        'Initialization'\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.transform = transform\n",
    "        self.indexes = np.arange(len(data))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return len(self.data) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        \n",
    "        # Generate data\n",
    "        x_batch = self.data[indexes]\n",
    "        y_batch = self.targets[indexes]\n",
    "        \n",
    "        # Perform transformation\n",
    "        if self.transform is not None:\n",
    "            x_batch = np.array([self.transform(row) for row in x_batch])\n",
    "\n",
    "        # Result        \n",
    "        return x_batch, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)        \n",
    "\n",
    "# Assuming 'data' and 'targets' are loaded numpy arrays\n",
    "# For example, let's create some random data similar to the PyTorch example:\n",
    "# data = np.random.randn(100, 64, 64, 3)  # 100 RGB images of size 64x64\n",
    "data = np.random.randn(10, 2)  # rows, cols = 100, 2\n",
    "targets = np.random.randint(0, 10, size=(10,))  # 100 target labels from 0 to 9\n",
    "\n",
    "# Create the Keras data generator\n",
    "keras_generator = KerasDataGenerator(data, targets, batch_size=4, shuffle=True)\n",
    "\n",
    "# Iterate over the dataset and print the elements\n",
    "for x, y in keras_generator:\n",
    "    print(f\"x: {x}, {type(x)}, y: {y}, {type(y)}\")\n",
    "\n",
    "# Use the generator to train a Keras model\n",
    "#model.fit(keras_generator, epochs=10)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(1, activation='sigmoid', input_shape=(2,))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "epochs = 5\n",
    "model.fit(keras_generator, epochs=epochs)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(keras_generator)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(keras_generator)\n",
    "for pred, (x, y) in zip(predictions, keras_generator):\n",
    "    print(f\"Input: {x}, True Label: {y}, Predicted Label: {pred[0]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
