{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cc284bb-7b02-4a1d-9de4-e4cac06f0581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7d912f8-2ee7-462f-903e-80a7d0c93daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path where the MNIST data will be downloaded\n",
    "image_path = './local_training_data'\n",
    "\n",
    "# Define a transform to convert the images to PyTorch tensors\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Download the MNIST training dataset\n",
    "mnist_dataset = torchvision.datasets.MNIST(\n",
    "    root=image_path, \n",
    "    train=True, \n",
    "    transform=transform, \n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "mnist_valid_dataset = Subset(mnist_dataset, torch.arange(10000))\n",
    "mnist_train_dataset = Subset(mnist_dataset, torch.arange(10000, len(mnist_dataset)))\n",
    "\n",
    "# Download the MNIST test dataset\n",
    "mnist_test_dataset = torchvision.datasets.MNIST(\n",
    "    root=image_path, \n",
    "    train=False, \n",
    "    transform=transform, \n",
    "    download=False  # Set to False assuming it's already downloaded\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e9d3d97-9d08-4afe-8389-a78e0eaa73ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming mnist_train_dataset and mnist_valid_dataset are already defined\n",
    "train_ds = mnist_train_dataset\n",
    "valid_ds = mnist_valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a2c7f54-f12d-424f-aa5d-e5a2444f91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the sequential model\n",
    "model = nn.Sequential()\n",
    "\n",
    "# Add the first convolutional layer\n",
    "model.add_module('conv1', nn.Conv2d(\n",
    "    in_channels=1, \n",
    "    out_channels=32, \n",
    "    kernel_size=5, \n",
    "    padding=2\n",
    "))\n",
    "\n",
    "# Add a ReLU activation layer\n",
    "model.add_module('relu1', nn.ReLU())\n",
    "\n",
    "# Add the first pooling layer\n",
    "model.add_module('pool1', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "# Add the second convolutional layer\n",
    "model.add_module('conv2', nn.Conv2d(\n",
    "    in_channels=32, \n",
    "    out_channels=64, \n",
    "    kernel_size=5, \n",
    "    padding=2\n",
    "))\n",
    "\n",
    "# Add another ReLU activation layer\n",
    "model.add_module('relu2', nn.ReLU())\n",
    "\n",
    "# Add the second pooling layer\n",
    "model.add_module('pool2', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "# Add a flatten layer to the model\n",
    "model.add_module('flatten', nn.Flatten())\n",
    "\n",
    "# Add fully connected layers with a dropout layer in between\n",
    "model.add_module('fc1', nn.Linear(3136, 1024))\n",
    "model.add_module('relu3', nn.ReLU())\n",
    "model.add_module('dropout', nn.Dropout(p=0.5))\n",
    "model.add_module('fc2', nn.Linear(1024, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6494a679-402d-4b1c-b485-322c6b810e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model: torch.nn.Module,\n",
    "                train_ds: TensorDataset,\n",
    "                loss_fn: nn.Module,\n",
    "                optimizer: optim.Optimizer,\n",
    "                valid_ds: TensorDataset,\n",
    "                accuracy_fn = None,\n",
    "                num_epochs = 100,\n",
    "                batch_size = 32,\n",
    "                seed = 1,\n",
    "                transform_pred = None,\n",
    "                device: torch.device = \"cpu\"):\n",
    "    # variables\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs    \n",
    "    torch.manual_seed(seed)\n",
    "    train_dl = DataLoader(dataset=train_ds, batch_size=batch_size, shuffle=True)\n",
    "    valid_dl = None\n",
    "    if valid_ds:\n",
    "        valid_dl = DataLoader(dataset=valid_ds, batch_size=batch_size, shuffle=True)\n",
    "    n_train = len(train_dl.dataset)    \n",
    "    # set model to device\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        # set model to training mode\n",
    "        model.train()\n",
    "        # mini-batch training\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            # Send data to device\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(x_batch)\n",
    "            if transform_pred:\n",
    "                y_pred = transform_pred(y_pred)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "            # Do backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if accuracy_fn:\n",
    "                accuracy_batch = accuracy_fn(y_pred, y_batch)\n",
    "                accuracy_hist_train[epoch] += accuracy_batch\n",
    "            loss_hist_train[epoch] += loss.item()            \n",
    "\n",
    "        # Compute store loss and accuracy as percent\n",
    "        loss_hist_train[epoch] /= n_train\n",
    "        accuracy_hist_train[epoch] /= n_train\n",
    "        \n",
    "        if valid_dl:\n",
    "            n_valid = len(valid_dl.dataset)\n",
    "            # set model to training mode\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for x_batch, y_batch in valid_dl:                    \n",
    "                    # Send data to device\n",
    "                    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "                    # Forward pass\n",
    "                    y_pred = model(x_batch)\n",
    "                    if transform_pred:\n",
    "                        y_pred = transform_pred(y_pred)\n",
    "\n",
    "                    # Compute loss\n",
    "                    loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "                    if accuracy_fn:\n",
    "                        accuracy_batch = accuracy_fn(y_pred, y_batch)\n",
    "                        accuracy_hist_valid[epoch] += accuracy_batch\n",
    "                    loss_hist_valid[epoch] += loss.item()\n",
    "\n",
    "                # Compute store loss and accuracy valid as percent\n",
    "                accuracy_hist_valid[epoch] /= n_valid\n",
    "                loss_hist_valid[epoch] /= n_valid\n",
    "                    \n",
    "        # Print out\n",
    "        if epoch % 10 == 0:\n",
    "            if valid_dl:\n",
    "                print(f\"Train loss: {loss_hist_train[epoch]:.5f} | Train accuracy: {accuracy_hist_train[epoch]:.2f}% | Val loss: {loss_hist_valid[epoch]:.5f} | Val accuracy: {accuracy_hist_valid[epoch]:.2f}%\")\n",
    "            else:\n",
    "                print(f\"Train loss: {loss_hist_train[epoch]:.5f} | Train accuracy: {accuracy_hist_train[epoch]:.2f}%\")\n",
    "\n",
    "    # Return result    \n",
    "    return (loss_hist_train, accuracy_hist_train, loss_hist_valid, accuracy_hist_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ab652f4-c7dc-4602-9648-e4beccd03d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_sum_multiclass(y_pred, y):\n",
    "    is_correct = (torch.argmax(y_pred, dim=1) == y).float()\n",
    "    accuracy = is_correct.sum()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33070a70-817d-419a-a41d-e1b0f058771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19731fd7-a423-48a2-be37-aeb9cfae4066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.00244 | Train accuracy: 0.95% | Val loss: 0.00112 | Val accuracy: 0.98%\n",
      "Train loss: 0.00017 | Train accuracy: 1.00% | Val loss: 0.00060 | Val accuracy: 0.99%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss_hist_train, accuracy_hist_train, loss_hist_valid, accuracy_hist_valid \u001b[38;5;241m=\u001b[39m \u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                                                       \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                                                       \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                                                                       \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                                                                       \u001b[49m\u001b[43mvalid_ds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                                                                       \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                                                                       \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                                                                       \u001b[49m\u001b[43maccuracy_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_accuracy_sum_multiclass\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 34\u001b[0m, in \u001b[0;36mfit_model\u001b[0;34m(model, train_ds, loss_fn, optimizer, valid_ds, accuracy_fn, num_epochs, batch_size, seed, transform_pred, device)\u001b[0m\n\u001b[1;32m     31\u001b[0m x_batch, y_batch \u001b[38;5;241m=\u001b[39m x_batch\u001b[38;5;241m.\u001b[39mto(device), y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform_pred:\n\u001b[1;32m     36\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m transform_pred(y_pred)\n",
      "File \u001b[0;32m~/python/ml-tutorials/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/python/ml-tutorials/venv/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/python/ml-tutorials/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/python/ml-tutorials/venv/lib/python3.9/site-packages/torch/nn/modules/pooling.py:166\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python/ml-tutorials/venv/lib/python3.9/site-packages/torch/_jit_internal.py:484\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python/ml-tutorials/venv/lib/python3.9/site-packages/torch/nn/functional.py:782\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    781\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[0;32m--> 782\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_hist_train, accuracy_hist_train, loss_hist_valid, accuracy_hist_valid = fit_model(model, \n",
    "                                                                                       train_ds,\n",
    "                                                                                       loss_fn, \n",
    "                                                                                       optimizer,\n",
    "                                                                                       valid_ds=valid_ds,\n",
    "                                                                                       num_epochs = 20,\n",
    "                                                                                       batch_size=64, \n",
    "                                                                                       accuracy_fn=get_accuracy_sum_multiclass)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
